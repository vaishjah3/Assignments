{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfCnSQDb5SxOEeDJNgTUbY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishjah3/Assignments/blob/main/MNIST_handwritten_digits_feedforward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "f1eKhJXpKrg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=784\n",
        "hidden_size=400\n",
        "output_size=10\n",
        "epochs=10\n",
        "batch_size=100\n",
        "learning_rate=0.001"
      ],
      "metadata": {
        "id": "7IKMupz2LN3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.MNIST(root='./data',\n",
        "                             train=True,\n",
        "                             transform=transforms.ToTensor(),\n",
        "                             download=True\n",
        "                        )\n",
        "test_dataset=datasets.MNIST(root='./data',\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            train=False\n",
        "                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5qMhysILvsq",
        "outputId": "18dcbef7-fc09-4091-b822-4e7714e3b1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 83428739.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 16382971.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 88165668.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2702202.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False)\n"
      ],
      "metadata": {
        "id": "uQJsxXbRMklY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1=nn.Linear(input_size, hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.fc2=nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3=nn.Linear(hidden_size, output_size)\n",
        "  def forward(self, x):\n",
        "    out=self.fc1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.fc2(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.fc3(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "ViO2e0TdY5m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=Net(input_size, hidden_size, output_size)\n",
        "CUDA=torch.cuda.is_available()\n",
        "if CUDA:\n",
        "  net=net.cuda()\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "lXilZJJbav55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_loader:\n",
        "  print(x.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYGI7LjLsvRz",
        "outputId": "6600f29e-1ff1-479e-a309-560900fec2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n"
      ],
      "metadata": {
        "id": "KI0DKpGrxNKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the network\n",
        "for epoch in range(epochs):\n",
        "  correct_train=0\n",
        "  running_loss=0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    #image size from (100,1,28,28) to (100,768)\n",
        "    images=images.view(-1, 784)\n",
        "    if CUDA:\n",
        "      images.cuda()\n",
        "      labels.cuda()\n",
        "    outputs=net(images)\n",
        "    #print(outputs.size())\n",
        "    #print(outputs)\n",
        "    _, predicted=torch.max(outputs.data, 1) #first_ndex (max_value), 2nd index(index of max_value)\n",
        "    #print(predicted)\n",
        "    correct_train += (predicted==labels).sum()\n",
        "    loss=criterion(outputs,labels)\n",
        "    #print(type(loss))\n",
        "    running_loss+=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch [{}/{}], Training Loss: {:.3f}, Training Accuracy: {:.3f}%'.format\n",
        "          (epoch+1, epochs, running_loss/len(train_loader), (100*correct_train.double()/len(train_dataset))))\n",
        "\n",
        "print(\"DONE TRAINING!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIQHA_5Tf_uB",
        "outputId": "3c6b1a86-2f91-4899-9733-9676454846d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 61.195%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 61.360%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 61.525%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 61.692%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 61.858%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.025%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.190%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.355%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.522%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.688%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 62.853%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.020%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.185%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.348%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.515%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.682%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 63.848%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.015%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.182%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.347%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.512%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.675%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 64.842%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 65.008%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 65.173%\n",
            "Epoch [2/10], Training Loss: 0.015, Training Accuracy: 65.338%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 65.505%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 65.670%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 65.837%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.002%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.165%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.332%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.498%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.658%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.825%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 66.988%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.153%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.320%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.485%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.652%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.817%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 67.983%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.150%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.312%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.477%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.643%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.808%\n",
            "Epoch [2/10], Training Loss: 0.016, Training Accuracy: 68.975%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.140%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.302%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.467%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.628%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.795%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 69.960%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.125%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.292%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.457%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.623%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.788%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 70.952%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.118%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.283%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.448%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.613%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.780%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 71.947%\n",
            "Epoch [2/10], Training Loss: 0.017, Training Accuracy: 72.113%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 72.275%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 72.440%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 72.607%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 72.765%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 72.932%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.098%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.262%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.425%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.590%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.755%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 73.922%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.087%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.252%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.418%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.585%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.750%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 74.913%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.077%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.242%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.408%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.575%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.742%\n",
            "Epoch [2/10], Training Loss: 0.018, Training Accuracy: 75.905%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.070%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.233%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.400%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.565%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.732%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 76.897%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.060%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.227%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.392%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.558%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.723%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 77.890%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.052%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.218%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.383%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.550%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.717%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 78.883%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.050%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.215%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.380%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.545%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.712%\n",
            "Epoch [2/10], Training Loss: 0.019, Training Accuracy: 79.875%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.040%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.207%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.372%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.538%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.703%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 80.868%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.035%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.202%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.367%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.533%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.700%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 81.867%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.032%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.198%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.365%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.528%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.692%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 82.858%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.022%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.188%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.355%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.520%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.685%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 83.848%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 84.015%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 84.180%\n",
            "Epoch [2/10], Training Loss: 0.020, Training Accuracy: 84.345%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 84.512%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 84.677%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 84.842%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.007%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.172%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.337%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.503%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.670%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 85.835%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.002%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.168%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.333%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.497%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.658%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.823%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 86.988%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.153%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.317%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.483%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.650%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.815%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 87.980%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 88.147%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 88.312%\n",
            "Epoch [2/10], Training Loss: 0.021, Training Accuracy: 88.477%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 88.642%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 88.808%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 88.973%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.140%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.307%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.473%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.638%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.800%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 89.962%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.128%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.290%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.453%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.618%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.782%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 90.948%\n",
            "Epoch [2/10], Training Loss: 0.022, Training Accuracy: 91.113%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 91.280%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 91.447%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 91.613%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 91.780%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 91.947%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.112%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.277%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.443%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.608%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.775%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 92.940%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.105%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.272%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.437%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.603%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.770%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 93.933%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.100%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.263%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.427%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.593%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.760%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 94.927%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.092%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.258%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.423%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.590%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.757%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 95.923%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 96.090%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 96.255%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 96.420%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 96.585%\n",
            "Epoch [2/10], Training Loss: 0.023, Training Accuracy: 96.752%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 96.918%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.085%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.248%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.413%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.578%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.743%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 97.910%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.075%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.240%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.407%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.573%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.737%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 98.900%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 99.067%\n",
            "Epoch [2/10], Training Loss: 0.024, Training Accuracy: 99.233%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.167%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.332%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.498%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.665%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.830%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 0.997%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.163%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.328%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.495%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.662%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.827%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 1.993%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.158%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.323%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.490%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.657%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.823%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 2.990%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.155%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.320%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.487%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.653%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.820%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 3.983%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 4.150%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 4.313%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 4.480%\n",
            "Epoch [3/10], Training Loss: 0.000, Training Accuracy: 4.647%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 4.813%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 4.980%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.147%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.312%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.477%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.642%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.808%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 5.975%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.142%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.308%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.475%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.638%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.802%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 6.968%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.135%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.300%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.463%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.630%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.797%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 7.963%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.130%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.297%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.463%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.627%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.793%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 8.958%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.125%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.292%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.458%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.623%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.790%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 9.957%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.123%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.290%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.457%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.622%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.787%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 10.953%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.118%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.285%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.452%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.618%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.785%\n",
            "Epoch [3/10], Training Loss: 0.001, Training Accuracy: 11.948%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.112%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.277%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.443%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.610%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.777%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 12.940%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.107%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.272%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.438%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.605%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.770%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 13.937%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.102%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.267%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.433%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.598%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.765%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 14.932%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.098%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.265%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.432%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.597%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.763%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 15.930%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.097%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.263%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.428%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.593%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.760%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 16.927%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.093%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.258%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.423%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.590%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.757%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 17.923%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 18.088%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 18.255%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 18.422%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 18.587%\n",
            "Epoch [3/10], Training Loss: 0.002, Training Accuracy: 18.752%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 18.915%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.080%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.247%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.413%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.577%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.743%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 19.910%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.075%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.242%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.407%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.573%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.738%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 20.905%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.070%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.235%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.397%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.562%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.728%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 21.893%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.060%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.225%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.392%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.557%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.723%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 22.888%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 23.053%\n",
            "Epoch [3/10], Training Loss: 0.003, Training Accuracy: 23.218%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 23.385%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 23.552%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 23.718%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 23.885%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.052%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.218%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.385%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.550%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.717%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 24.883%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.050%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.215%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.382%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.547%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.713%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 25.880%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.047%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.213%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.380%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.547%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.713%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 26.878%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.045%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.212%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.378%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.542%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.707%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 27.873%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.040%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.207%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.373%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.538%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.703%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 28.870%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.037%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.203%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.368%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.535%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.702%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 29.868%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.035%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.200%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.367%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.533%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.700%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 30.867%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.032%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.198%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.365%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.532%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.697%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 31.863%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 32.030%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 32.195%\n",
            "Epoch [3/10], Training Loss: 0.004, Training Accuracy: 32.362%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 32.523%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 32.690%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 32.855%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.020%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.187%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.353%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.513%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.678%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 33.845%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.012%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.178%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.345%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.512%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.678%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 34.843%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.010%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.172%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.337%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.503%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.665%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.832%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 35.998%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 36.165%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 36.332%\n",
            "Epoch [3/10], Training Loss: 0.005, Training Accuracy: 36.498%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 36.662%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 36.827%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 36.992%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.158%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.323%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.490%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.655%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.815%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 37.982%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.147%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.308%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.475%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.640%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.807%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 38.972%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 39.137%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 39.300%\n",
            "Epoch [3/10], Training Loss: 0.006, Training Accuracy: 39.467%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 39.630%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 39.793%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 39.958%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.122%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.288%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.453%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.620%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.785%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 40.950%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.115%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.282%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.447%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.612%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.775%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 41.942%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.105%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.272%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.435%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.602%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.768%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 42.932%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 43.098%\n",
            "Epoch [3/10], Training Loss: 0.007, Training Accuracy: 43.265%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 43.430%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 43.593%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 43.757%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 43.920%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.083%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.248%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.415%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.582%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.747%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 44.913%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.078%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.243%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.408%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.573%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.740%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 45.905%\n",
            "Epoch [3/10], Training Loss: 0.008, Training Accuracy: 46.068%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 46.230%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 46.395%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 46.562%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 46.725%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 46.890%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.057%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.222%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.383%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.548%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.715%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 47.882%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 48.045%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 48.210%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 48.377%\n",
            "Epoch [3/10], Training Loss: 0.009, Training Accuracy: 48.542%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 48.707%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 48.872%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.038%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.205%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.370%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.537%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.703%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 49.870%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.037%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.203%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.370%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.537%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.700%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 50.867%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.033%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.200%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.363%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.527%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.690%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 51.852%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.013%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.180%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.347%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.510%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.677%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 52.842%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 53.008%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 53.175%\n",
            "Epoch [3/10], Training Loss: 0.010, Training Accuracy: 53.338%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 53.503%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 53.668%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 53.835%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.000%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.165%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.330%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.495%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.660%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.827%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 54.993%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.160%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.325%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.492%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.658%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.823%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 55.988%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.153%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.318%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.485%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.652%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.815%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 56.977%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 57.143%\n",
            "Epoch [3/10], Training Loss: 0.011, Training Accuracy: 57.308%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 57.473%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 57.640%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 57.807%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 57.973%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.140%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.307%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.473%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.640%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.803%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 58.967%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.130%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.295%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.462%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.627%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.793%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 59.960%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.125%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.292%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.458%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.625%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.792%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 60.958%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.125%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.288%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.455%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.620%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.785%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 61.952%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 62.118%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 62.285%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 62.448%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 62.615%\n",
            "Epoch [3/10], Training Loss: 0.012, Training Accuracy: 62.778%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 62.942%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.107%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.273%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.438%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.603%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.770%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 63.937%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.103%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.270%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.433%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.600%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.767%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 64.932%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.098%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.265%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.430%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.597%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.763%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 65.930%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.095%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.260%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.425%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.592%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.758%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 66.925%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.092%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.258%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.425%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.592%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.758%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 67.925%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.092%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.258%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.425%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.590%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.755%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 68.920%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.087%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.253%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.420%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.583%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.750%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 69.917%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 70.083%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 70.247%\n",
            "Epoch [3/10], Training Loss: 0.013, Training Accuracy: 70.413%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 70.580%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 70.747%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 70.913%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.078%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.242%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.408%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.575%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.742%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 71.907%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.072%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.238%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.403%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.570%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.737%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 72.903%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.070%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.237%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.402%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.568%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.733%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 73.900%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.067%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.233%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.398%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.563%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.730%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 74.895%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.060%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.227%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.393%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.558%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.722%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 75.888%\n",
            "Epoch [3/10], Training Loss: 0.014, Training Accuracy: 76.055%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 76.220%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 76.387%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 76.552%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 76.717%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 76.883%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.050%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.217%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.382%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.548%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.715%\n",
            "Epoch [3/10], Training Loss: 0.015, Training Accuracy: 77.882%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 80.855%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.020%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.187%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.353%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.518%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.683%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 81.845%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.012%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.178%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.345%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.507%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.672%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.832%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 82.998%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 83.165%\n",
            "Epoch [3/10], Training Loss: 0.016, Training Accuracy: 83.332%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 83.497%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 83.663%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 83.830%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 83.993%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.157%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.322%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.487%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.652%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.815%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 84.982%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.145%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.308%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.475%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.640%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.807%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 85.973%\n",
            "Epoch [3/10], Training Loss: 0.017, Training Accuracy: 86.137%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 86.302%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 86.465%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 86.630%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 86.795%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 86.962%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.127%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.290%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.457%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.620%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.785%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 87.952%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.118%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.280%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.447%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.612%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.778%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 88.945%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.110%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.277%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.442%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.603%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.770%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 89.937%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 90.102%\n",
            "Epoch [3/10], Training Loss: 0.018, Training Accuracy: 90.267%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 90.432%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 90.598%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 90.765%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 90.928%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.093%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.258%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.425%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.587%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.753%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 91.920%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.085%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.252%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.418%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.583%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.750%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 92.917%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.083%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.248%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.415%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.582%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.745%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 93.912%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 94.075%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 94.238%\n",
            "Epoch [3/10], Training Loss: 0.019, Training Accuracy: 94.405%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 94.570%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 94.737%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 94.898%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.062%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.227%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.392%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.558%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.725%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 95.890%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.057%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.222%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.388%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.555%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.720%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 96.885%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 97.050%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 97.215%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 97.380%\n",
            "Epoch [3/10], Training Loss: 0.020, Training Accuracy: 97.547%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 97.712%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 97.878%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.045%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.212%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.378%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.545%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.710%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 98.875%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 99.040%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 99.207%\n",
            "Epoch [3/10], Training Loss: 0.021, Training Accuracy: 99.372%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.165%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.332%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.497%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.663%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.827%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 0.992%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.158%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.323%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.490%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.655%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.820%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 1.987%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.148%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.315%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.482%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.648%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.815%\n",
            "Epoch [4/10], Training Loss: 0.000, Training Accuracy: 2.982%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.147%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.312%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.477%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.642%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.808%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 3.975%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.142%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.307%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.470%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.637%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.802%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 4.968%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.135%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.302%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.468%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.635%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.800%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 5.965%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.132%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.298%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.465%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.630%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.795%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 6.960%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.127%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.293%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.460%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.627%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.793%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 7.958%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.125%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.292%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.457%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.622%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.788%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 8.955%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.120%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.287%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.452%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.617%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.783%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 9.950%\n",
            "Epoch [4/10], Training Loss: 0.001, Training Accuracy: 10.117%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 10.278%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 10.445%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 10.612%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 10.778%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 10.945%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.112%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.278%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.442%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.608%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.775%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 11.940%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.105%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.272%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.438%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.605%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.772%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 12.938%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.105%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.272%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.438%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.603%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.770%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 13.937%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.102%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.268%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.433%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.600%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.765%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 14.930%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.097%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.262%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.427%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.593%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.760%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 15.927%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.092%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.258%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.423%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.590%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.757%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 16.923%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.090%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.257%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.423%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.590%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.757%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 17.920%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.085%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.252%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.418%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.585%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.752%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 18.917%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.083%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.248%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.413%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.580%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.747%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 19.913%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 20.080%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 20.245%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 20.410%\n",
            "Epoch [4/10], Training Loss: 0.002, Training Accuracy: 20.577%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 20.742%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 20.908%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.073%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.240%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.407%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.573%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.740%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 21.905%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.072%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.238%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.405%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.572%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.735%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 22.902%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.068%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.235%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.400%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.565%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.732%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 23.898%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.065%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.228%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.395%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.562%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.725%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 24.892%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.058%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.225%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.392%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.558%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.725%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 25.890%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.053%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.220%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.385%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.552%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.718%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 26.882%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.048%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.213%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.380%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.547%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.712%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 27.878%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.045%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.212%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.378%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.545%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.710%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 28.877%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 29.043%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 29.210%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 29.377%\n",
            "Epoch [4/10], Training Loss: 0.003, Training Accuracy: 29.543%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 29.708%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 29.875%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.042%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.208%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.375%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.542%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.707%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 30.872%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.038%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.203%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.368%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.535%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.700%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 31.867%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.032%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.198%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.363%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.530%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.697%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 32.860%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.027%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.192%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.358%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.523%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.685%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 33.852%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.018%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.185%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.352%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.518%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.683%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 34.850%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 35.015%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 35.182%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 35.348%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 35.515%\n",
            "Epoch [4/10], Training Loss: 0.004, Training Accuracy: 35.682%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 35.845%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.012%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.177%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.343%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.508%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.675%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 36.840%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.005%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.172%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.338%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.503%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.670%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 37.837%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.003%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.168%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.335%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.502%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.668%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 38.835%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.000%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.165%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.332%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.497%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.663%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.828%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 39.992%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.158%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.325%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.488%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.655%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.818%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 40.983%\n",
            "Epoch [4/10], Training Loss: 0.005, Training Accuracy: 41.150%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 41.315%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 41.480%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 41.645%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 41.812%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 41.977%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.142%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.307%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.473%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.638%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.803%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 42.968%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.133%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.300%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.465%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.632%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.798%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 43.965%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.127%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.292%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.455%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.622%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.787%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 44.953%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 45.117%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 45.282%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 45.448%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 45.615%\n",
            "Epoch [4/10], Training Loss: 0.006, Training Accuracy: 45.782%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 45.947%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.112%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.277%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.443%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.610%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.777%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 46.942%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.103%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.270%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.433%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.600%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.763%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 47.927%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.093%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.260%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.427%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.592%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.758%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 48.925%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.092%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.257%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.423%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.590%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.757%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 49.923%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 50.090%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 50.257%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 50.420%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 50.587%\n",
            "Epoch [4/10], Training Loss: 0.007, Training Accuracy: 50.752%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 50.915%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.080%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.245%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.412%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.577%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.742%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 51.908%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.075%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.240%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.402%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.567%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.732%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 52.897%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.063%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.228%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.395%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.560%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.723%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 53.890%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.055%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.220%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.387%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.553%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.720%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 54.887%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 55.052%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 55.218%\n",
            "Epoch [4/10], Training Loss: 0.008, Training Accuracy: 55.385%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 55.550%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 55.715%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 55.882%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.047%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.212%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.378%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.545%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.712%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 56.878%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.043%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.207%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.373%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.540%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.707%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 57.873%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.038%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.203%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.370%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.535%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.702%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 58.867%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.033%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.198%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.365%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.532%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.697%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 59.863%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.028%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.193%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.358%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.525%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.688%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 60.852%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 61.018%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 61.185%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 61.352%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 61.518%\n",
            "Epoch [4/10], Training Loss: 0.009, Training Accuracy: 61.685%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 61.847%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.013%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.180%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.345%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.508%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.675%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 62.840%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.007%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.172%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.338%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.505%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.672%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 63.838%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.005%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.170%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.335%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.502%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.668%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 64.835%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.000%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.167%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.333%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.500%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.667%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.832%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 65.998%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.163%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.330%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.497%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.663%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.828%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 66.995%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.162%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.327%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.493%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.658%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.825%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 67.990%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.155%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.320%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.487%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.653%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.820%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 68.987%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 69.153%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 69.320%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 69.487%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 69.652%\n",
            "Epoch [4/10], Training Loss: 0.010, Training Accuracy: 69.817%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 69.982%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.143%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.310%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.473%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.640%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.807%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 70.972%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.138%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.305%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.470%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.637%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.803%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 71.965%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.132%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.298%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.462%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.625%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.790%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 72.955%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 73.122%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 73.288%\n",
            "Epoch [4/10], Training Loss: 0.011, Training Accuracy: 73.453%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 73.620%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 73.787%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 73.953%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.118%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.285%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.452%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.618%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.785%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 74.948%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.115%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.280%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.445%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.610%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.773%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 75.938%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.102%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.267%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.432%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.598%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.765%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 76.930%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.093%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.260%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.427%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.590%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.753%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 77.920%\n",
            "Epoch [4/10], Training Loss: 0.012, Training Accuracy: 78.085%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 78.250%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 78.417%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 78.582%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 78.747%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 78.912%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.073%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.230%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.395%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.560%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.723%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 79.888%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 80.055%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 80.220%\n",
            "Epoch [4/10], Training Loss: 0.013, Training Accuracy: 80.383%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 80.548%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 80.713%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 80.878%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.043%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.210%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.375%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.542%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.708%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 81.873%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.038%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.205%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.370%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.535%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.702%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 82.867%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.032%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.195%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.362%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.528%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.695%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 83.862%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 84.027%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 84.192%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 84.358%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 84.523%\n",
            "Epoch [4/10], Training Loss: 0.014, Training Accuracy: 84.687%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 84.852%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.015%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.180%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.347%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.513%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.677%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 85.843%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.010%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.175%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.342%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.505%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.672%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 86.838%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.002%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.165%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.332%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.498%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.663%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.830%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 87.997%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.163%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.328%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.495%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.660%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.822%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 88.988%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 89.153%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 89.318%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 89.483%\n",
            "Epoch [4/10], Training Loss: 0.015, Training Accuracy: 89.650%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 89.815%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 89.982%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.147%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.310%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.477%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.643%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.810%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 90.975%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.142%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.307%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.472%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.638%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.803%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 91.968%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.135%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.302%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.468%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.635%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.800%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 92.965%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.132%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.297%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.458%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.625%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.790%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 93.955%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 94.122%\n",
            "Epoch [4/10], Training Loss: 0.016, Training Accuracy: 94.288%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 94.453%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 94.618%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 94.785%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 94.948%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.115%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.280%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.445%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.608%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.775%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 95.940%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.105%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.268%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.433%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.597%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.763%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 96.930%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 97.095%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 97.257%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 97.423%\n",
            "Epoch [4/10], Training Loss: 0.017, Training Accuracy: 97.588%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 97.750%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 97.917%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.080%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.247%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.413%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.580%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.745%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 98.912%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 99.078%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 99.240%\n",
            "Epoch [4/10], Training Loss: 0.018, Training Accuracy: 99.405%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.167%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.333%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.500%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.667%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.832%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 0.998%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.165%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.332%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.497%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.662%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.827%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 1.990%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.155%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.322%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.488%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.655%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.822%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 2.988%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 3.153%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 3.320%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 3.487%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 3.652%\n",
            "Epoch [5/10], Training Loss: 0.000, Training Accuracy: 3.818%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 3.982%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.148%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.315%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.480%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.643%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.810%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 4.977%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.143%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.310%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.473%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.637%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.803%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 5.970%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.137%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.302%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.468%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.635%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.802%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 6.968%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.135%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.300%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.463%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.630%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.792%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 7.958%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.125%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.292%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.457%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.623%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.790%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 8.957%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.123%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.290%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.455%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.620%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.787%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 9.953%\n",
            "Epoch [5/10], Training Loss: 0.001, Training Accuracy: 10.117%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 10.282%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 10.448%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 10.615%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 10.782%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 10.948%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.115%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.282%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.447%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.612%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.777%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 11.942%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.107%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.273%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.438%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.603%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.770%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 12.937%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.102%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.267%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.430%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.595%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.762%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 13.927%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.093%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.258%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.425%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.588%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.753%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 14.920%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.087%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.253%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.420%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.587%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.753%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 15.920%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.087%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.253%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.418%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.585%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.750%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 16.917%\n",
            "Epoch [5/10], Training Loss: 0.002, Training Accuracy: 17.083%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 17.242%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 17.408%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 17.572%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 17.738%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 17.905%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.072%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.237%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.403%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.570%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.737%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 18.902%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.068%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.235%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.402%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.563%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.730%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 19.895%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.062%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.228%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.392%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.558%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.723%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 20.890%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.057%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.223%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.390%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.557%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.723%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 21.890%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.057%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.223%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.390%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.557%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.723%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 22.890%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.053%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.220%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.387%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.552%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.718%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 23.885%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.050%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.215%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.380%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.547%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.713%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 24.880%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 25.045%\n",
            "Epoch [5/10], Training Loss: 0.003, Training Accuracy: 25.210%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 25.375%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 25.538%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 25.705%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 25.870%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.037%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.202%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.367%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.532%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.698%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 26.863%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.030%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.197%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.363%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.530%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.697%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 27.863%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.030%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.197%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.363%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.530%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.695%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 28.860%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.025%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.190%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.357%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.522%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.687%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 29.853%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.018%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.185%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.350%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.515%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.682%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 30.848%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.012%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.178%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.345%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.512%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.677%\n",
            "Epoch [5/10], Training Loss: 0.004, Training Accuracy: 31.843%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.007%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.173%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.340%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.507%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.673%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 32.837%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.000%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.167%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.333%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.500%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.667%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 33.833%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.000%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.167%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.332%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.497%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.662%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.827%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 34.993%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.158%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.325%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.492%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.658%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.825%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 35.988%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.155%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.322%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.488%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.652%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.818%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 36.985%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.152%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.318%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.485%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.652%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.818%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 37.985%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.152%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.318%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.485%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.650%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.817%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 38.983%\n",
            "Epoch [5/10], Training Loss: 0.005, Training Accuracy: 39.150%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 39.315%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 39.482%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 39.648%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 39.815%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 39.982%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.148%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.315%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.480%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.647%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.812%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 40.978%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.143%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.310%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.475%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.642%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.808%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 41.973%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.140%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.307%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.472%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.637%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.802%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 42.967%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.130%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.295%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.460%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.625%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.792%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 43.958%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.123%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.290%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.455%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.622%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.788%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 44.953%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.120%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.287%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.450%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.617%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.783%\n",
            "Epoch [5/10], Training Loss: 0.006, Training Accuracy: 45.950%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.115%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.280%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.445%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.612%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.778%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 46.945%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.112%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.278%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.445%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.610%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.777%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 47.943%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.108%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.273%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.438%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.603%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.770%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 48.937%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.103%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.268%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.435%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.600%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.767%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 49.932%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.098%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.263%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.430%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.597%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.763%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 50.928%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.092%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.257%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.423%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.588%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.753%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 51.918%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.085%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.252%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.418%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.585%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.752%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 52.918%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.085%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.252%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.417%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.582%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.748%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 53.913%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 54.080%\n",
            "Epoch [5/10], Training Loss: 0.007, Training Accuracy: 54.247%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 54.410%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 54.575%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 54.742%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 54.908%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.075%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.242%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.408%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.575%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.742%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 55.908%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.072%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.238%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.403%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.568%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.735%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 56.902%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.068%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.235%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.402%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.567%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.733%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 57.898%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.063%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.230%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.395%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.562%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.727%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 58.893%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.058%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.223%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.387%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.552%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.717%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 59.882%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.048%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.215%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.380%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.545%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.712%\n",
            "Epoch [5/10], Training Loss: 0.008, Training Accuracy: 60.878%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.042%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.207%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.372%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.538%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.703%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 61.870%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.035%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.200%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.367%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.533%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.700%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 62.867%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.032%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.198%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.365%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.530%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.697%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 63.863%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.030%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.193%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.360%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.525%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.692%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 64.858%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.023%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.190%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.355%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.522%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.688%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 65.855%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.020%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.187%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.353%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.518%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.685%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 66.850%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 67.017%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 67.180%\n",
            "Epoch [5/10], Training Loss: 0.009, Training Accuracy: 67.345%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 67.508%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 67.675%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 67.840%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.005%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.172%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.337%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.503%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.670%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 68.835%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.000%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.165%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.330%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.497%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.660%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.825%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 69.990%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.155%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.320%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.487%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.652%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.817%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 70.982%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 71.148%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 71.312%\n",
            "Epoch [5/10], Training Loss: 0.010, Training Accuracy: 71.478%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 71.643%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 71.807%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 71.972%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.138%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.303%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.468%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.633%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.797%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 72.963%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.128%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.295%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.460%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.623%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.788%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 73.955%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.122%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.285%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.452%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.618%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.783%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 74.950%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.117%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.283%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.450%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.613%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.778%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 75.945%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.112%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.278%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.443%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.608%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.775%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 76.942%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 77.105%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 77.272%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 77.438%\n",
            "Epoch [5/10], Training Loss: 0.011, Training Accuracy: 77.605%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 77.770%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 77.937%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.103%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.270%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.437%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.603%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.767%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 78.933%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.100%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.267%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.433%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.598%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.765%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 79.930%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.097%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.263%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.430%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.595%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.762%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 80.928%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.095%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.262%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.428%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.595%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.760%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 81.925%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.090%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.257%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.423%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.590%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.755%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 82.918%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.085%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.250%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.417%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.583%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.748%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 83.915%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.082%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.245%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.410%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.577%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.742%\n",
            "Epoch [5/10], Training Loss: 0.012, Training Accuracy: 84.908%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.073%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.240%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.407%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.573%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.740%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 85.905%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.072%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.237%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.403%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.568%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.735%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 86.902%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.068%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.230%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.395%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.560%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.727%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 87.892%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.058%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.223%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.388%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.553%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.718%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 88.883%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.050%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.213%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.380%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.545%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.712%\n",
            "Epoch [5/10], Training Loss: 0.013, Training Accuracy: 89.878%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.043%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.208%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.370%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.535%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.700%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 90.865%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.028%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.195%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.358%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.523%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.690%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 91.857%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.020%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.187%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.353%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.518%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.683%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 92.848%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.013%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.180%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.345%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.512%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.675%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 93.840%\n",
            "Epoch [5/10], Training Loss: 0.014, Training Accuracy: 94.005%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.170%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.337%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.502%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.667%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.830%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 94.997%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.163%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.328%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.495%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.662%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.827%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 95.993%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.155%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.322%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.488%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.653%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.820%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 96.987%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.153%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.320%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.487%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.652%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.818%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 97.983%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 98.148%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 98.315%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 98.482%\n",
            "Epoch [5/10], Training Loss: 0.015, Training Accuracy: 98.645%\n",
            "Epoch [5/10], Training Loss: 0.016, Training Accuracy: 98.807%\n",
            "Epoch [5/10], Training Loss: 0.016, Training Accuracy: 98.972%\n",
            "Epoch [5/10], Training Loss: 0.016, Training Accuracy: 99.137%\n",
            "Epoch [5/10], Training Loss: 0.016, Training Accuracy: 99.300%\n",
            "Epoch [5/10], Training Loss: 0.016, Training Accuracy: 99.467%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.167%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.333%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.498%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.663%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.827%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 0.987%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.153%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.320%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.487%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.652%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.818%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 1.985%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 2.150%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 2.317%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 2.482%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 2.648%\n",
            "Epoch [6/10], Training Loss: 0.000, Training Accuracy: 2.815%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 2.980%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.147%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.312%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.478%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.643%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.807%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 3.972%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.137%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.303%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.470%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.637%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.802%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 4.968%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.133%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.300%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.467%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.632%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.798%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 5.965%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.130%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.297%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.462%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.627%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.793%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 6.960%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 7.125%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 8.455%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 8.620%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 8.785%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 8.952%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 9.118%\n",
            "Epoch [6/10], Training Loss: 0.001, Training Accuracy: 9.282%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 9.447%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 9.613%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 9.780%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 9.947%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.113%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.280%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.440%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.607%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.773%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 10.940%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.105%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.270%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.433%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.600%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.767%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 11.933%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.100%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.267%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.433%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.600%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.767%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 12.928%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.092%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.258%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.423%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.588%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.755%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 13.920%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.087%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.253%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.420%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.587%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.752%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 14.918%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 15.083%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 15.248%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 15.413%\n",
            "Epoch [6/10], Training Loss: 0.002, Training Accuracy: 15.580%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 15.742%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 15.908%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.075%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.242%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.408%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.575%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.742%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 16.908%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.072%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.237%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.403%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.570%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.737%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 17.903%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.070%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.235%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.402%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.568%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.735%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 18.902%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.068%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.235%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.402%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.568%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.735%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 19.902%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.068%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.235%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.400%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.567%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.733%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 20.898%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.063%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.230%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.397%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.563%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.730%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 21.897%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.062%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.228%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.393%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.560%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.727%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 22.893%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.058%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.225%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.392%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.558%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.723%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 23.890%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.055%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.222%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.388%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.555%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.722%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 24.888%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 25.055%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 25.222%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 25.387%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 25.550%\n",
            "Epoch [6/10], Training Loss: 0.003, Training Accuracy: 25.717%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 25.882%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.048%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.215%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.382%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.548%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.715%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 26.882%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.047%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.212%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.378%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.543%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.707%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 27.873%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.040%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.207%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.373%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.540%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.707%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 28.872%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.038%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.205%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.368%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.535%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.702%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 29.868%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.033%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.198%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.365%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.532%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.698%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 30.863%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.030%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.195%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.358%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.523%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.688%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 31.855%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.022%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.188%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.355%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.522%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.688%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 32.852%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.018%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.183%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.350%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.517%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.683%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 33.850%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 34.017%\n",
            "Epoch [6/10], Training Loss: 0.004, Training Accuracy: 34.183%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 34.348%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 34.515%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 34.682%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 34.847%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.013%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.178%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.343%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.510%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.677%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 35.843%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.010%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.175%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.342%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.508%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.675%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 36.842%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.005%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.172%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.338%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.505%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.672%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 37.838%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.005%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.172%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.338%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.505%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.672%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 38.838%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.005%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.172%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.337%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.503%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.670%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 39.835%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.002%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.168%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.335%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.498%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.665%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.830%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 40.995%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.162%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.328%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.495%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.662%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.827%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 41.992%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.155%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.320%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.485%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.650%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.817%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 42.983%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 43.150%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 43.315%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 43.482%\n",
            "Epoch [6/10], Training Loss: 0.005, Training Accuracy: 43.648%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 43.813%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 43.980%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.147%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.312%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.478%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.643%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.808%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 44.975%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.140%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.307%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.473%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.638%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.805%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 45.970%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.137%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.303%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.467%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.633%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.800%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 46.967%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.132%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.298%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.463%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.630%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.797%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 47.960%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.127%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.293%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.460%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.627%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.793%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 48.960%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.127%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.293%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.460%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.627%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.793%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 49.960%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.127%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.292%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.458%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.625%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.790%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 50.957%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.123%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.290%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.455%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.620%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.787%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 51.953%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.118%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.283%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.450%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.615%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.782%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 52.948%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 53.115%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 53.282%\n",
            "Epoch [6/10], Training Loss: 0.006, Training Accuracy: 53.448%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 53.613%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 53.778%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 53.945%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.112%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.278%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.445%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.612%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.777%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 54.942%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.108%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.275%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.440%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.607%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.773%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 55.938%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.105%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.270%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.437%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.603%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.770%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 56.937%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.103%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.270%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.433%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.600%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.767%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 57.932%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.098%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.263%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.427%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.590%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.757%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 58.923%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.090%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.257%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.423%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.588%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.755%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 59.922%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.085%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.250%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.417%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.582%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.748%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 60.910%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 61.077%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 61.243%\n",
            "Epoch [6/10], Training Loss: 0.007, Training Accuracy: 61.410%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 61.575%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 61.742%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 61.908%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.072%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.238%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.403%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.570%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.737%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 62.900%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.067%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.233%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.400%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.567%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.732%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 63.895%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.062%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.227%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.392%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.558%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.723%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 64.890%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.057%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.222%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.388%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.552%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.717%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 65.882%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 66.048%\n",
            "Epoch [6/10], Training Loss: 0.008, Training Accuracy: 66.213%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 66.377%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 66.538%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 66.703%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 66.868%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.035%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.202%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.367%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.533%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.698%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 67.865%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.032%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.197%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.363%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.530%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.695%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 68.862%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.028%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.195%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.360%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.525%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.690%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 69.857%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.023%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.188%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.355%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.522%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.687%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 70.853%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.018%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.183%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.348%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.513%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.678%\n",
            "Epoch [6/10], Training Loss: 0.009, Training Accuracy: 71.845%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.008%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.173%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.340%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.507%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.673%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 72.838%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.005%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.172%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.337%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.503%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.668%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 73.833%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.000%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.165%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.332%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.498%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.665%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.830%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 74.995%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.158%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.323%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.488%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.655%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.822%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 75.985%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.152%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.317%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.483%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.647%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.813%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 76.980%\n",
            "Epoch [6/10], Training Loss: 0.010, Training Accuracy: 77.145%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 77.308%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 77.475%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 77.640%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 77.807%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 77.973%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.138%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.305%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.472%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.638%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.805%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 78.972%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.138%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.305%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.470%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.635%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.802%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 79.968%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.135%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.302%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.468%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.635%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.800%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 80.967%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.133%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.297%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.462%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.628%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.792%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 81.958%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.123%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.287%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.452%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.618%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.783%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 82.950%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.117%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.282%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.448%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.612%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.778%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 83.945%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.112%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.278%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.445%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.612%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.777%\n",
            "Epoch [6/10], Training Loss: 0.011, Training Accuracy: 84.942%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.103%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.270%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.437%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.603%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.768%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 85.935%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.102%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.268%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.435%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.602%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.768%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 86.933%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.100%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.267%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.432%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.598%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.763%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 87.928%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.095%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.262%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.427%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.592%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.758%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 88.923%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.090%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.257%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.422%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.587%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.753%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 89.920%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.087%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.252%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.418%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.585%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.752%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 90.917%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.083%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.250%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.417%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.583%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.750%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 91.917%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.082%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.248%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.413%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.580%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.747%\n",
            "Epoch [6/10], Training Loss: 0.012, Training Accuracy: 92.912%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.077%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.242%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.408%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.575%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.742%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 93.908%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.073%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.238%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.402%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.568%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.732%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 94.898%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.063%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.230%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.397%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.562%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.725%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 95.892%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.057%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.223%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.387%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.553%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.720%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 96.887%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.052%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.217%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.382%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.547%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.713%\n",
            "Epoch [6/10], Training Loss: 0.013, Training Accuracy: 97.880%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.047%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.213%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.377%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.543%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.710%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 98.875%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 99.042%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 99.208%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 99.372%\n",
            "Epoch [6/10], Training Loss: 0.014, Training Accuracy: 99.538%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.165%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.332%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.498%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.665%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.830%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 0.997%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.163%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.328%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.492%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.658%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.825%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 1.990%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.157%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.323%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.490%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.657%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.822%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 2.987%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.153%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.318%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.485%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.652%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.818%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 3.983%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.147%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.312%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.478%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.645%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.812%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 4.978%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 5.145%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 5.312%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 5.478%\n",
            "Epoch [7/10], Training Loss: 0.000, Training Accuracy: 5.645%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 5.810%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 5.975%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.142%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.308%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.472%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.638%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.805%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 6.972%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.138%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.305%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.472%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.638%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.805%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 7.970%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.137%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.303%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.468%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.635%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.802%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 8.967%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.133%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.298%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.465%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.632%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.798%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 9.963%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.130%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.297%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.463%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.630%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.797%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 10.963%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.130%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.297%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.463%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.628%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.793%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 11.960%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.127%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.292%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.458%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.625%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.792%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 12.957%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.123%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.290%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.457%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.623%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.790%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 13.957%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.123%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.290%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.457%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.623%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.788%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 14.953%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.120%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.285%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.450%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.617%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.783%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 15.950%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.117%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.278%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.445%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.612%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.778%\n",
            "Epoch [7/10], Training Loss: 0.001, Training Accuracy: 16.945%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.107%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.273%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.440%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.605%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.772%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 17.938%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.105%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.272%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.438%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.605%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.772%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 18.935%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.100%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.265%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.427%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.592%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.758%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 19.925%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.092%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.258%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.425%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.592%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.757%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 20.923%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.087%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.253%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.420%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.585%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.752%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 21.918%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.085%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.250%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.415%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.580%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.747%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 22.913%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.078%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.245%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.412%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.577%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.742%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 23.908%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 24.075%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 24.242%\n",
            "Epoch [7/10], Training Loss: 0.002, Training Accuracy: 24.408%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 24.572%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 24.738%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 24.905%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.072%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.237%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.402%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.568%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.733%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 25.900%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.067%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.233%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.400%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.567%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.733%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 26.900%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.063%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.227%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.393%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.558%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.725%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 27.890%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.057%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.223%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.387%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.552%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.718%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 28.885%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.048%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.215%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.378%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.545%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.712%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 29.877%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.043%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.210%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.375%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.540%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.707%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 30.873%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 31.037%\n",
            "Epoch [7/10], Training Loss: 0.003, Training Accuracy: 31.202%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 31.367%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 31.533%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 31.700%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 31.865%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.030%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.197%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.363%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.530%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.695%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 32.862%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.028%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.193%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.360%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.525%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.692%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 33.857%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.023%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.188%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.355%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.522%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.688%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 34.855%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.022%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.187%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.352%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.515%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.680%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 35.845%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.008%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.175%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.342%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.508%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.675%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 36.842%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.008%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.173%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.338%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.503%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.670%\n",
            "Epoch [7/10], Training Loss: 0.004, Training Accuracy: 37.835%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.002%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.168%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.332%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.498%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.665%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.830%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 38.997%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.163%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.330%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.495%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.662%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.828%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 39.993%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.158%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.325%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.492%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.655%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.817%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 40.983%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.148%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.315%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.482%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.648%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.813%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 41.980%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.147%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.313%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.478%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.645%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.810%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 42.973%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.138%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.303%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.470%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.635%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.802%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 43.968%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.135%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.302%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.467%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.632%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.798%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 44.965%\n",
            "Epoch [7/10], Training Loss: 0.005, Training Accuracy: 45.130%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 45.295%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 45.462%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 45.628%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 45.795%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 45.962%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.128%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.293%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.458%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.625%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.792%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 46.958%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.123%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.290%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.455%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.622%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.788%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 47.955%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.120%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.287%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.452%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.618%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.785%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 48.952%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.118%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.285%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.452%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.618%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.785%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 49.950%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.117%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.283%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.450%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.617%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.783%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 50.950%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.117%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.283%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.450%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.617%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.783%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 51.950%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.117%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.283%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.450%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.617%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.783%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 52.950%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.117%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.283%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.447%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.610%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.773%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 53.938%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.105%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.270%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.437%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.603%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.770%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 54.935%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.102%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.267%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.432%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.598%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.765%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 55.932%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 56.098%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 56.265%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 56.432%\n",
            "Epoch [7/10], Training Loss: 0.006, Training Accuracy: 56.598%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 56.762%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 56.928%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.095%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.260%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.427%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.590%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.757%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 57.923%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.090%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.257%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.423%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.588%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.753%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 58.918%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.085%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.252%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.418%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.582%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.747%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 59.913%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.078%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.243%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.410%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.577%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.743%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 60.908%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.075%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.242%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.407%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.573%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.738%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 61.905%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.072%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.238%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.405%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.572%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.737%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 62.900%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.062%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.228%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.392%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.558%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.723%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 63.888%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 64.053%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 64.218%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 64.385%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 64.552%\n",
            "Epoch [7/10], Training Loss: 0.007, Training Accuracy: 64.718%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 64.885%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.050%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.213%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.378%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.545%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.712%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 65.877%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.043%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.207%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.372%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.537%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.702%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 66.867%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.032%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.195%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.362%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.528%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.695%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 67.860%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.027%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.193%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.360%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.527%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.693%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 68.860%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.027%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.193%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.360%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.525%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.692%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 69.857%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.023%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.188%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.355%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.520%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.687%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 70.853%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 71.020%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 71.187%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 71.353%\n",
            "Epoch [7/10], Training Loss: 0.008, Training Accuracy: 71.518%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 71.683%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 71.850%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.017%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.182%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.348%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.515%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.682%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 72.848%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.015%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.182%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.347%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.513%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.680%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 73.847%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.013%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.180%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.343%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.510%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.677%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 74.843%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.010%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.177%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.343%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.510%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.677%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 75.843%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.008%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.173%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.340%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.505%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.667%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.830%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 76.995%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.162%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.328%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.492%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.658%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.822%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 77.988%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 78.155%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 78.320%\n",
            "Epoch [7/10], Training Loss: 0.009, Training Accuracy: 78.485%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 78.650%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 78.817%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 78.982%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.148%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.313%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.480%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.647%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.813%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 79.975%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.142%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.305%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.472%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.638%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.805%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 80.972%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.137%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.302%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.468%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.635%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.802%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 81.967%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.132%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.298%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.465%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.628%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.795%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 82.957%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 83.123%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 83.287%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 83.453%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 83.620%\n",
            "Epoch [7/10], Training Loss: 0.010, Training Accuracy: 83.787%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 83.952%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.117%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.282%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.440%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.603%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.768%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 84.933%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.098%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.260%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.423%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.590%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.757%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 85.923%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 86.090%\n",
            "Epoch [7/10], Training Loss: 0.011, Training Accuracy: 86.255%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 86.420%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 86.585%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 86.750%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 86.913%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.080%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.247%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.408%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.570%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.733%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 87.900%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.065%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.230%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.397%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.560%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.727%\n",
            "Epoch [7/10], Training Loss: 0.012, Training Accuracy: 88.892%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.053%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.220%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.387%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.553%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.717%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 89.880%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.047%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.210%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.377%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.540%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.707%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 90.873%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.040%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.205%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.372%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.538%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.702%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 91.867%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.033%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.197%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.363%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.528%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.695%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 92.858%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.023%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.190%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.355%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.520%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.687%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 93.852%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 94.018%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 94.185%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 94.352%\n",
            "Epoch [7/10], Training Loss: 0.013, Training Accuracy: 94.518%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 94.683%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 94.847%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.013%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.178%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.342%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.507%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.673%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 95.840%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.007%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.173%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.340%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.505%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.670%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 96.837%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.002%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.167%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.333%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.498%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.665%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.832%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 97.998%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.165%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.332%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.498%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.665%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.828%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 98.992%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 99.158%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 99.323%\n",
            "Epoch [7/10], Training Loss: 0.014, Training Accuracy: 99.485%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 0.167%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 0.333%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 0.500%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 0.667%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 0.833%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.000%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.167%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.330%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.493%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.660%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.827%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 1.993%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.160%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.327%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.492%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.657%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.823%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 2.990%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.157%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.322%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.488%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.655%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.822%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 3.988%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.155%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.322%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.488%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.653%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.820%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 4.987%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.152%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.318%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.485%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.652%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.818%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 5.985%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.152%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.318%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.485%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.652%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.817%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 6.983%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 7.150%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 7.317%\n",
            "Epoch [8/10], Training Loss: 0.000, Training Accuracy: 7.483%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 8.978%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.143%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.310%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.477%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.643%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.810%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 9.973%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.138%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.305%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.470%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.633%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.800%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 10.967%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.132%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.298%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.465%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.630%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.795%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 11.962%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.128%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.295%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.462%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.628%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.795%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 12.962%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.127%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.293%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.460%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.627%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.793%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 13.960%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.125%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.292%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.458%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.625%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.792%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 14.957%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.122%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.288%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.455%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.622%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.788%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 15.955%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.122%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.288%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.452%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.618%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.785%\n",
            "Epoch [8/10], Training Loss: 0.001, Training Accuracy: 16.952%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.117%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.283%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.450%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.617%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.782%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 17.947%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.113%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.280%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.445%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.612%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.778%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 18.945%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.110%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.275%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.442%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.608%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.775%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 19.940%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.107%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.273%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.440%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.607%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.773%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 20.940%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.107%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.273%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.440%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.607%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.773%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 21.940%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.105%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.272%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.438%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.605%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.772%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 22.938%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.105%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.270%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.437%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.603%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.768%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 23.933%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.100%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.267%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.433%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.600%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.765%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 24.930%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.095%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.260%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.425%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.590%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.757%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 25.923%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.090%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.255%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.422%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.588%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.755%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 26.922%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.088%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.255%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.422%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.588%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.753%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 27.915%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.082%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.248%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.413%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.578%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.743%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 28.910%\n",
            "Epoch [8/10], Training Loss: 0.002, Training Accuracy: 29.077%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 29.242%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 29.408%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 29.575%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 29.738%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 29.902%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.068%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.235%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.400%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.565%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.732%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 30.897%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.062%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.228%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.395%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.560%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.727%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 31.893%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.055%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.222%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.387%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.553%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.720%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 32.887%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.053%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.220%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.387%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.553%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.720%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 33.887%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 34.053%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 34.217%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 34.383%\n",
            "Epoch [8/10], Training Loss: 0.003, Training Accuracy: 34.548%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 34.713%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 34.880%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.047%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.213%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.380%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.547%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.712%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 35.878%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.045%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.212%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.377%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.543%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.708%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 36.875%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.042%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.208%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.375%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.542%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.707%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 37.872%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.038%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.205%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.370%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.535%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.702%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 38.868%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.033%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.200%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.367%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.532%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.697%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 39.862%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.028%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.195%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.360%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.525%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.690%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 40.857%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.023%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.190%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.355%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.522%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.688%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 41.855%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.022%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.188%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.353%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.520%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.687%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 42.852%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.018%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.185%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.352%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.518%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.685%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 43.852%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.017%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.183%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.350%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.515%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.680%\n",
            "Epoch [8/10], Training Loss: 0.004, Training Accuracy: 44.847%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.012%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.178%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.345%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.512%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.678%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 45.845%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.008%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.175%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.342%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.508%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.675%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 46.842%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.007%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.173%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.340%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.507%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.672%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 47.837%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.003%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.167%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.333%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.500%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.667%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.833%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 48.998%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.165%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.328%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.495%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.662%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.827%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 49.990%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 50.157%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 50.323%\n",
            "Epoch [8/10], Training Loss: 0.005, Training Accuracy: 50.488%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 50.653%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 50.820%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 50.985%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.150%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.315%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.482%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.648%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.815%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 51.982%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.147%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.313%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.478%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.642%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.808%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 52.973%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.140%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.307%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.470%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.635%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.800%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 53.967%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.133%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.298%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.465%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.632%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.795%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 54.962%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 55.127%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 55.292%\n",
            "Epoch [8/10], Training Loss: 0.006, Training Accuracy: 55.457%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 55.622%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 55.788%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 55.955%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.122%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.287%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.453%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.618%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.783%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 56.950%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.115%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.282%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.448%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.613%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.780%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 57.945%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.110%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.275%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.442%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.608%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.775%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 58.940%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.105%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.270%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.437%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.602%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.768%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 59.933%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.100%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.267%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.433%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.600%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.767%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 60.933%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.097%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.263%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.428%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.595%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.760%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 61.927%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.093%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.260%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.425%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.588%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.753%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 62.920%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.085%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.252%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.418%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.585%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.750%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 63.917%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.083%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.250%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.415%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.582%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.748%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 64.915%\n",
            "Epoch [8/10], Training Loss: 0.007, Training Accuracy: 65.082%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 65.247%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 65.412%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 65.578%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 65.745%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 65.912%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.077%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.242%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.407%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.573%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.738%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 66.905%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.070%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.237%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.402%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.568%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.735%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 67.898%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.065%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.230%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.397%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.563%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.730%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 68.895%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.062%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.227%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.392%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.558%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.725%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 69.892%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.058%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.225%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.390%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.555%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.722%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 70.888%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.055%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.220%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.387%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.552%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.718%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 71.885%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 72.050%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 72.217%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 72.383%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 72.547%\n",
            "Epoch [8/10], Training Loss: 0.008, Training Accuracy: 72.713%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 72.880%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.045%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.212%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.377%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.540%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.707%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 73.873%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.040%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.207%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.373%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.540%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.707%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 74.872%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.038%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.205%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.372%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.538%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.703%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 75.870%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.037%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.203%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.370%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.537%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.703%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 76.868%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.035%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.202%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.368%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.535%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.700%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 77.865%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.030%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.195%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.362%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.528%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.693%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 78.860%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.025%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.192%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.358%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.525%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.692%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 79.858%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.025%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.190%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.355%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.522%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.688%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 80.853%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.018%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.185%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.352%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.518%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.683%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 81.848%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 82.015%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 82.182%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 82.345%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 82.510%\n",
            "Epoch [8/10], Training Loss: 0.009, Training Accuracy: 82.677%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 82.840%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.002%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.168%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.335%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.502%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.667%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.833%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 83.997%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.163%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.330%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.493%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.658%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.825%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 84.992%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.158%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.325%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.492%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.658%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.825%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 85.988%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.155%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.322%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.488%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.653%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.818%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 86.983%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.148%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.315%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.482%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.648%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.815%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 87.982%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.148%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.313%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.478%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.642%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.808%\n",
            "Epoch [8/10], Training Loss: 0.010, Training Accuracy: 88.975%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.140%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.305%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.470%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.637%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.803%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 89.970%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.137%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.302%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.468%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.633%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.800%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 90.967%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.133%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.300%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.463%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.630%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.797%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 91.963%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.128%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.295%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.462%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.627%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.793%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 92.960%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.127%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.293%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.460%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.627%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.793%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 93.960%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.127%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.293%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.460%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.625%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.792%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 94.958%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.125%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.290%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.457%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.623%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.790%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 95.957%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.123%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.290%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.457%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.620%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.787%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 96.953%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.120%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.287%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.453%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.620%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.787%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 97.953%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.120%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.285%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.450%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.615%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.780%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 98.947%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 99.113%\n",
            "Epoch [8/10], Training Loss: 0.011, Training Accuracy: 99.280%\n",
            "Epoch [8/10], Training Loss: 0.012, Training Accuracy: 99.445%\n",
            "Epoch [8/10], Training Loss: 0.012, Training Accuracy: 99.610%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.167%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.333%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.500%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.667%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.833%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 0.998%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.163%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.330%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.495%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.662%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.828%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 1.995%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.162%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.328%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.493%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.660%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.827%\n",
            "Epoch [9/10], Training Loss: 0.000, Training Accuracy: 2.993%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.158%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.325%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.492%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.658%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.825%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 3.992%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.157%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.323%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.490%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.655%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.822%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 4.988%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.155%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.320%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.485%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.652%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.818%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 5.985%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.152%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.318%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.485%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.652%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.818%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 6.983%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.150%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.317%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.483%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.650%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.817%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 7.983%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.150%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.317%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.480%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.647%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.813%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 8.980%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.145%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.310%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.477%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.642%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.808%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 9.975%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.142%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.308%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.473%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.640%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.805%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 10.972%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.138%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.305%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.472%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.637%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.802%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 11.965%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.132%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.298%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.465%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.630%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.797%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 12.963%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.130%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.297%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.463%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.630%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.797%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 13.963%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 14.130%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 14.297%\n",
            "Epoch [9/10], Training Loss: 0.001, Training Accuracy: 14.463%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 14.628%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 14.795%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 14.962%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.128%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.295%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.462%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.627%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.793%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 15.960%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.125%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.292%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.458%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.625%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.790%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 16.957%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.123%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.290%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.455%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.622%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.788%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 17.953%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.120%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.287%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.453%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.617%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.782%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 18.948%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.115%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.280%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.447%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.612%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.778%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 19.945%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.112%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.278%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.445%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.610%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.777%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 20.943%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.110%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.277%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.443%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.608%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.775%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 21.938%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.105%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.272%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.438%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.605%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.772%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 22.938%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 23.103%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 23.270%\n",
            "Epoch [9/10], Training Loss: 0.002, Training Accuracy: 23.437%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 23.602%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 23.767%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 23.933%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.100%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.265%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.432%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.598%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.765%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 24.932%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.098%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.265%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.432%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.598%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.765%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 25.932%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.098%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.263%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.430%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.597%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.763%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 26.930%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.095%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.262%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.428%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.595%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.762%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 27.928%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.093%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.258%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.425%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.590%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.757%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 28.923%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.088%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.252%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.418%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.583%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.748%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 29.915%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.082%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.248%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.415%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.582%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.747%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 30.912%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.078%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.245%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.412%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.578%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.743%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 31.910%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.077%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.243%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.410%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.577%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.742%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 32.908%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.075%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.240%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.407%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.573%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.740%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 33.907%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.073%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.237%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.403%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.570%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.737%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 34.903%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.070%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.237%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.403%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.570%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.737%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 35.903%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 36.070%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 36.237%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 36.403%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 36.568%\n",
            "Epoch [9/10], Training Loss: 0.003, Training Accuracy: 36.735%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 36.902%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.067%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.232%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.398%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.565%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.732%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 37.898%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.065%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.232%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.398%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.563%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.730%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 38.897%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.063%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.230%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.397%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.562%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.728%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 39.895%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.062%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.228%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.395%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.560%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.727%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 40.892%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.058%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.223%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.390%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.557%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.723%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 41.890%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.055%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.220%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.387%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.552%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.717%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 42.883%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.050%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.215%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.382%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.545%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.712%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 43.878%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.045%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.210%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.375%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.542%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.708%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 44.875%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.042%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.208%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.375%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.542%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.708%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 45.875%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.042%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.208%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.375%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.542%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.708%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 46.875%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.042%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.208%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.375%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.540%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.707%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 47.873%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.040%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.205%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.370%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.537%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.703%\n",
            "Epoch [9/10], Training Loss: 0.004, Training Accuracy: 48.870%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.033%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.200%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.367%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.533%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.698%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 49.865%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.032%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.197%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.363%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.530%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.693%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 50.860%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.025%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.192%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.357%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.523%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.690%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 51.855%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.022%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.188%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.355%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.520%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.687%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 52.853%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.020%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.185%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.352%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.518%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.685%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 53.848%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.015%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.180%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.347%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.513%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.680%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 54.847%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.012%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.177%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.343%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.508%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.675%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 55.842%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.007%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.173%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.340%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.507%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.672%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 56.838%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 57.005%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 57.172%\n",
            "Epoch [9/10], Training Loss: 0.005, Training Accuracy: 57.338%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 57.503%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 57.670%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 57.837%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.003%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.170%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.335%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.500%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.667%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 58.833%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.000%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.167%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.333%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.500%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.665%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.832%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 59.997%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.162%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.328%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.495%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.662%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.828%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 60.993%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.160%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.325%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.490%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.657%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.820%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 61.987%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.152%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.318%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.485%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.652%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.818%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 62.985%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.150%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.313%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.480%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.647%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.813%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 63.980%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.145%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.312%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.477%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.643%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.810%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 64.977%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.142%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.308%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.475%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.642%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.808%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 65.975%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 66.140%\n",
            "Epoch [9/10], Training Loss: 0.006, Training Accuracy: 66.307%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 66.472%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 66.638%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 66.802%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 66.968%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.135%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.302%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.467%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.633%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.797%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 67.962%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.127%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.293%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.460%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.623%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.790%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 68.957%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.123%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.290%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.455%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.622%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.787%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 69.953%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.120%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.287%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.453%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.620%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.782%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 70.948%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.115%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.282%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.448%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.615%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.782%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 71.945%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.112%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.278%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.445%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.612%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.778%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 72.945%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.112%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.277%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.442%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.608%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.775%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 73.942%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.108%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.272%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.438%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.603%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.770%\n",
            "Epoch [9/10], Training Loss: 0.007, Training Accuracy: 74.935%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.102%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.268%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.435%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.602%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.768%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 75.935%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.098%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.263%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.430%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.593%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.760%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 76.927%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.093%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.260%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.427%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.593%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.760%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 77.927%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.093%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.260%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.425%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.590%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.755%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 78.922%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.087%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.253%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.420%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.585%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.750%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 79.917%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.083%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.250%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.417%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.582%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.748%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 80.910%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.077%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.242%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.408%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.572%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.738%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 81.905%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.072%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.237%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.403%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.570%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.737%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 82.903%\n",
            "Epoch [9/10], Training Loss: 0.008, Training Accuracy: 83.070%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 83.235%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 83.402%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 83.567%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 83.733%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 83.900%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.065%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.232%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.398%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.565%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.732%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 84.898%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.065%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.232%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.398%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.565%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.732%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 85.898%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.065%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.232%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.397%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.563%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.728%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 86.893%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.060%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.225%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.392%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.558%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.725%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 87.892%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.055%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.222%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.388%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.553%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.720%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 88.885%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.052%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.218%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.385%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.548%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.715%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 89.882%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.045%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.210%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.375%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.538%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.705%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 90.872%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.038%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.203%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.370%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.537%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.703%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 91.870%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.035%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.202%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.368%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.535%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.702%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 92.868%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.035%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.202%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.367%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.533%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.698%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 93.865%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.032%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.198%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.365%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.532%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.697%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 94.863%\n",
            "Epoch [9/10], Training Loss: 0.009, Training Accuracy: 95.030%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 95.195%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 95.362%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 95.525%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 95.692%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 95.857%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.023%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.190%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.357%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.523%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.690%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 96.855%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.022%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.187%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.352%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.518%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.685%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 97.847%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.012%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.178%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.345%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.512%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.678%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 98.843%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 99.010%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 99.177%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 99.343%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 99.507%\n",
            "Epoch [9/10], Training Loss: 0.010, Training Accuracy: 99.673%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.165%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.330%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.497%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.662%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.828%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 0.995%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.162%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.328%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.495%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.662%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.828%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 1.995%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.160%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.325%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.492%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.657%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.822%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 2.988%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.155%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.322%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.488%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.655%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.822%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 3.985%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.152%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.318%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.485%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.652%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.818%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 4.983%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.150%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.317%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.483%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.650%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.817%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 5.983%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.150%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.317%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.482%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.648%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.815%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 6.982%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 7.148%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 7.315%\n",
            "Epoch [10/10], Training Loss: 0.000, Training Accuracy: 7.482%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 7.648%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 7.813%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 7.978%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.145%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.310%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.477%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.643%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.810%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 8.977%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.143%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.308%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.475%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.642%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.807%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 9.973%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.140%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.307%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.473%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.640%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.807%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 10.973%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.140%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.307%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.473%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.640%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.807%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 11.973%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.140%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.307%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.473%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.640%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.807%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 12.973%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.140%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.307%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.473%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.640%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.807%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 13.973%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.140%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.307%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.473%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.638%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.805%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 14.970%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.137%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.303%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.470%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.637%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.803%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 15.968%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.135%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.302%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.468%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.635%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.802%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 16.968%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.133%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.300%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.467%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.633%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.798%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 17.965%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.132%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.298%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.465%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.632%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.797%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 18.963%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.130%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.297%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.463%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.630%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.797%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 19.963%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.130%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.297%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.463%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.630%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.797%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 20.963%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.130%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.297%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.463%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.628%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.793%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 21.960%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.123%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.290%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.457%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.620%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.787%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 22.953%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.120%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.287%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.452%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.618%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.785%\n",
            "Epoch [10/10], Training Loss: 0.001, Training Accuracy: 23.952%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.117%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.283%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.450%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.617%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.780%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 24.943%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.110%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.277%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.443%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.610%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.777%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 25.943%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.110%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.277%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.443%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.610%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.775%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 26.942%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.108%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.275%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.440%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.607%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.773%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 27.940%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.107%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.272%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.435%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.602%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.768%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 28.935%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.098%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.265%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.430%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.593%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.760%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 29.927%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.093%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.258%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.425%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.592%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.758%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 30.923%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 31.090%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 31.255%\n",
            "Epoch [10/10], Training Loss: 0.002, Training Accuracy: 31.422%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 31.588%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 31.753%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 31.917%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.080%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.247%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.413%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.578%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.745%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 32.912%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.078%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.245%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.412%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.577%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.743%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 33.910%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.077%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.243%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.410%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.573%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.740%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 34.905%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.070%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.237%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.403%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.568%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.733%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 35.900%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.067%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.233%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.398%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.565%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.730%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 36.897%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.063%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.230%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.395%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.562%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.728%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 37.895%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.062%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.228%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.395%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.562%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.725%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 38.892%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.058%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.225%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.390%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.557%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.723%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 39.890%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.055%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.222%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.388%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.555%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.722%\n",
            "Epoch [10/10], Training Loss: 0.003, Training Accuracy: 40.887%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.053%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.220%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.387%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.553%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.720%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 41.885%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.052%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.218%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.383%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.548%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.715%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 42.880%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.047%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.213%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.378%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.545%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.710%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 43.875%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.042%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.208%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.375%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.542%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.708%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 44.875%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.040%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.207%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.373%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.538%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.705%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 45.872%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.038%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.205%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.372%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.538%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.705%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 46.872%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.038%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.205%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.370%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.537%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.703%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 47.870%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.037%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.203%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.370%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.535%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.702%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 48.868%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.033%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.200%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.367%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.533%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.700%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 49.867%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.033%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.200%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.367%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.533%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.700%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 50.865%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.030%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.195%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.360%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.527%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.693%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 51.860%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.027%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.193%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.360%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.523%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.690%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 52.855%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.022%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.188%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.355%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.522%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.688%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 53.855%\n",
            "Epoch [10/10], Training Loss: 0.004, Training Accuracy: 54.022%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 54.187%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 54.352%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 54.518%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 54.685%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 54.850%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.017%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.183%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.348%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.515%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.682%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 55.847%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.013%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.180%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.345%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.512%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.677%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 56.843%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.010%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.177%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.340%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.505%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.672%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 57.838%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.003%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.167%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.333%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.500%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.665%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.830%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 58.997%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.163%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.328%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.493%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.660%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.827%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 59.992%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.158%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.322%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.487%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.652%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.818%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 60.985%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 61.152%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 61.317%\n",
            "Epoch [10/10], Training Loss: 0.005, Training Accuracy: 61.483%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 61.648%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 61.813%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 61.980%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.147%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.312%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.475%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.642%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.805%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 62.970%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.137%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.303%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.470%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.637%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.802%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 63.968%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.133%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.297%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.463%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.630%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.793%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 64.960%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 65.127%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 65.292%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 65.455%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 65.622%\n",
            "Epoch [10/10], Training Loss: 0.006, Training Accuracy: 65.788%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 65.955%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.118%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.283%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.448%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.610%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.777%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 66.943%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.107%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.272%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.437%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.602%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.768%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 67.935%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.098%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.265%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.430%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.595%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.762%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 68.927%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 69.093%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 69.260%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 69.425%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 69.590%\n",
            "Epoch [10/10], Training Loss: 0.007, Training Accuracy: 69.757%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 69.918%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.083%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.248%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.415%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.582%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.747%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 70.912%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.077%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.243%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.407%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.572%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.738%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 71.903%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.070%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.237%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.403%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.567%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.733%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 72.898%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 73.065%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 73.232%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 73.397%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 73.563%\n",
            "Epoch [10/10], Training Loss: 0.008, Training Accuracy: 73.728%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 73.892%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.058%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.223%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.388%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.555%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.722%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 74.888%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.055%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.222%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.387%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.553%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.720%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 75.883%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.047%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.213%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.380%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.545%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.710%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 76.877%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.043%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.207%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.373%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.535%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.702%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 77.868%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.035%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.200%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.367%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.532%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.698%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 78.865%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 79.032%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 79.193%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 79.357%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 79.523%\n",
            "Epoch [10/10], Training Loss: 0.009, Training Accuracy: 79.690%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 79.857%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.023%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.190%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.355%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.522%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.687%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 80.852%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.018%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.183%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.350%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.517%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.683%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 81.848%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.015%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.180%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.345%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.512%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.677%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 82.843%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.008%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.175%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.340%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.505%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.670%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.833%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 83.998%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 84.165%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 84.332%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 84.498%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 84.662%\n",
            "Epoch [10/10], Training Loss: 0.010, Training Accuracy: 84.827%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 84.993%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.160%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.327%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.490%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.657%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.823%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 85.988%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.155%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.318%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.485%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.652%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.818%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 86.985%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.148%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.313%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.480%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.645%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.810%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 87.977%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.142%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.307%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.473%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.638%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.805%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 88.970%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.135%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.302%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.467%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.632%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.798%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 89.965%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.132%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.298%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.465%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.630%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.795%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 90.962%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 91.127%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 91.292%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 91.458%\n",
            "Epoch [10/10], Training Loss: 0.011, Training Accuracy: 91.622%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 91.785%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 91.950%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.115%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.282%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.448%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.612%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.778%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 92.945%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.110%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.277%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.443%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.608%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.775%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 93.942%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.107%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.272%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.438%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.600%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.767%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 94.933%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.097%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.263%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.430%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.597%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.760%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 95.925%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.092%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.258%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.423%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.588%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.755%\n",
            "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 96.922%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.085%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.252%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.418%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.585%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.752%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 97.917%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.082%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.248%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.413%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.578%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.745%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 98.912%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 99.077%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 99.242%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 99.408%\n",
            "Epoch [10/10], Training Loss: 0.013, Training Accuracy: 99.573%\n",
            "DONE TRAINING!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  for images, labels in test_loader:\n",
        "    if CUDA:\n",
        "      images.cuda()\n",
        "      labels.cuda()\n",
        "    images=images.view(-1, 28*28)\n",
        "    outputs=net(images)\n",
        "    _, predicted=torch.max(outputs.data, 1)\n",
        "    correct+=(predicted==labels).sum().item()\n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / len(test_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUwB2INmt0WZ",
        "outputId": "1e217a04-5e0d-4563-f9ea-f9de1ce0af09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.15 %\n"
          ]
        }
      ]
    }
  ]
}